{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chargement des modèles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import model_from_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charge un modèle Keras à partir de son fichier json et h5\n",
    "def model_loader(json_filepath, h5_filepath):    \n",
    "    json_file = open(json_filepath, 'r')\n",
    "    json_model = json_file.read()\n",
    "    json_file.close()\n",
    "    \n",
    "    model = model_from_json(json_model)\n",
    "    model.load_weights(h5_filepath)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_model = model_loader('modèles/image_model.json', 'modèles/image_model.h5')\n",
    "text_model = model_loader('modèles/text_model.json', 'modèles/text_model.h5')\n",
    "audio_model = model_loader('modèles/song_model.json', 'modèles/song_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fonctions de traitement des images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "import mediapipe as mp\n",
    "\n",
    "from moviepy.editor import VideoFileClip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dimension des images pour être traitées par le modèle\n",
    "IMG_WIDTH = 48\n",
    "IMG_HEIGHT = 48"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prédit l'émotion exprimée dans une image avec un modèle donné\n",
    "def predict_face_emotion(model, img):\n",
    "    # Listes des classes récupérées à partir du modèle\n",
    "    classes_name = ['angry', 'disgust', 'fear', 'happy', 'neutral', 'sad', 'surprise']\n",
    "    \n",
    "    # Image en niveaux de gris\n",
    "    img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    # Dimension de sortie souhaitée : (1, 48, 48, 1)\n",
    "    img_processed = np.expand_dims(img_gray, axis=(0, 3))\n",
    "    # Normalisation de la valeur des pixels dans [0, 1]\n",
    "    img_processed = img_processed / 255.0\n",
    "\n",
    "    # Prédiction du modèle sur l'image\n",
    "    emotion_scores = model.predict(img_processed)\n",
    "\n",
    "    # Récupération de l'indice de la valeur la plus élevée dans le vecteur de prédiction\n",
    "    predicted_emotion_index = np.argmax(emotion_scores)\n",
    "\n",
    "    # Récupération du nom de l'émotion\n",
    "    predicted_emotion_label = classes_name[predicted_emotion_index]\n",
    "\n",
    "    return predicted_emotion_index, predicted_emotion_label, emotion_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Affiche sur une image le visage détecté et l'émotion associée\n",
    "def process_image(frame, face_detection, model):\n",
    "    # Dimension de la frame\n",
    "    h, w, _ = frame.shape\n",
    "    \n",
    "    # Pixels au format RGB\n",
    "    img_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    output = face_detection.process(img_rgb)\n",
    "    \n",
    "    # Visages détectés sur l'image\n",
    "    if output.detections is not None:\n",
    "        for detection in output.detections:\n",
    "            location_data = detection.location_data\n",
    "            rbb = location_data.relative_bounding_box\n",
    "            \n",
    "            # Récupération des coordonnées du visage détecté\n",
    "            x, y, width, height = rbb.xmin, rbb.ymin, rbb.width, rbb.height\n",
    "            \n",
    "            x = int(x * w)\n",
    "            y = int(y * h)\n",
    "            width = int(width * w)\n",
    "            height = int(height * h)\n",
    "            \n",
    "            face_region = frame[y: y + height, x: x + width]\n",
    "            # Visage sur 48x48 pixels\n",
    "            face_resized = cv2.resize(face_region, (IMG_WIDTH, IMG_HEIGHT), interpolation=cv2.INTER_AREA)\n",
    "            \n",
    "            # Détection de l'émotion par le modèle\n",
    "            predicted_index, predicted_label, scores = predict_face_emotion(model, face_resized)\n",
    "            \n",
    "            # Ajout de l'émotion sur la frame\n",
    "            text_printed = predicted_label + ' : ' + str(np.round(scores[0][predicted_index], 3))\n",
    "            cv2.putText(frame, text_printed, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (36, 255, 12), 2)\n",
    "            \n",
    "            # Ajout d'une rectangle autour du visage détecté\n",
    "            cv2.rectangle(frame, (x, y), (x + width, y + height), (36, 255, 12), 2)\n",
    "            \n",
    "    return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_video(input_video_filepath, output_video_filepath, model):\n",
    "    temp_filepath = 'temp/temp_videofile.mp4'\n",
    "    \n",
    "    # Chargement de la vidéo, de l'audio et récupération des FPS de la vidéo\n",
    "    clip = VideoFileClip(input_video_filepath)\n",
    "    audio = clip.audio\n",
    "    fps = clip.fps\n",
    "    \n",
    "    # Détection des visages avec une confiance de 50%\n",
    "    mp_face_detection = mp.solutions.face_detection\n",
    "    with mp_face_detection.FaceDetection(model_selection=0, min_detection_confidence=0.5) as face_detection:\n",
    "        cap = cv2.VideoCapture(input_video_filepath)\n",
    "        \n",
    "        # Récupération et écriture de l'image\n",
    "        ret, frame = cap.read()\n",
    "        output_video = cv2.VideoWriter(temp_filepath, cv2.VideoWriter_fourcc(*'MP4V'), fps, (frame.shape[1], frame.shape[0]))\n",
    "\n",
    "        # Traitement de l'image\n",
    "        while ret:\n",
    "            frame = process_image(frame, face_detection, model)\n",
    "            output_video.write(frame)\n",
    "            ret, frame = cap.read()\n",
    "\n",
    "        cap.release()\n",
    "        output_video.release()\n",
    "        \n",
    "        # Rajout de l'audio dans la vidéo\n",
    "        output_video = VideoFileClip(temp_filepath)\n",
    "        output_video = output_video.set_audio(audio)\n",
    "        \n",
    "        # Ajout du son\n",
    "        output_video.write_videofile(output_video_filepath, codec='libx264', audio_codec='aac', fps=fps)\n",
    "        \n",
    "        # Suppression de la vidéo sans son\n",
    "        if os.path.exists(temp_filepath):\n",
    "            os.remove(temp_filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fonctions de traitement du texte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import speech_recognition as sr\n",
    "from deep_translator import GoogleTranslator\n",
    "\n",
    "import pickle\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from moviepy.video.io.ffmpeg_tools import ffmpeg_extract_subclip\n",
    "from moviepy.editor import VideoFileClip, ImageClip, concatenate_videoclips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transcription du texte à partir d'une vidéo\n",
    "def transcribe_video_audio(video_path, language='fr'):\n",
    "    transcribed_text = ''\n",
    "    recognizer = sr.Recognizer()\n",
    "\n",
    "    # Chargement de la vidéo et extraction du son\n",
    "    video_clip = VideoFileClip(video_path)\n",
    "    video_audio = video_clip.audio\n",
    "\n",
    "    # Conversion au format .wav\n",
    "    temp_audio_file = \"temp/temp_audio.wav\"\n",
    "    video_audio.write_audiofile(temp_audio_file)\n",
    "    \n",
    "    # Ouverture du fichier avec SpeechRecognition\n",
    "    with sr.AudioFile(temp_audio_file) as audio_file:\n",
    "        audio_data = recognizer.record(audio_file)\n",
    "\n",
    "        try:\n",
    "            if language == 'fr':\n",
    "                transcribed_text = recognizer.recognize_google(audio_data, language='fr-FR')\n",
    "            else:\n",
    "                transcribed_text = recognizer.recognize_google(audio_data)\n",
    "            # print(\"Transcription de l'audio en texte :\\n\", transcribed_text)\n",
    "        except sr.UnknownValueError:\n",
    "            print(\"Impossible de récupérer l'audio de la vidéo\")\n",
    "        except sr.RequestError as e:\n",
    "            print(f\"Erreur : {e}\")\n",
    "            \n",
    "    # Suppression du fichier temporaire\n",
    "    if os.path.exists(temp_audio_file):\n",
    "        os.remove(temp_audio_file)\n",
    "        \n",
    "    return transcribed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Traduction du français vers l'anglais\n",
    "def translate_french_to_english(text):\n",
    "    translated = GoogleTranslator(source='fr', target='en').translate(text)\n",
    "    return translated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retire les caractères spéciaux d'une chaîne de caractères\n",
    "def remove_special_chars(text):\n",
    "    return re.sub(r\"[^a-zA-Z0-9]\", \" \", text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Passe la casse du texte en minuscule\n",
    "def to_lowercase(text):\n",
    "    return text.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retire les 'stop words'\n",
    "def remove_stop_words(text):\n",
    "    words = text.split()\n",
    "    filtered_words = [word for word in words if word not in stop_words]\n",
    "    return ' '.join(filtered_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalisation du texte de la même manière que lors de l'entraînement du modèle\n",
    "def normalize_text(text):\n",
    "    # Tokenizer utilisé lors de l'entraînement du modèle\n",
    "    tokenizer_path = 'tokenizer.pkl'\n",
    "    # Taille maximale d'une phrase\n",
    "    max_length = 25\n",
    "    \n",
    "    # Chargement du tokenizer\n",
    "    with open(tokenizer_path, 'rb') as file:\n",
    "        tokenizer = pickle.load(file)\n",
    "        \n",
    "    # Nettoyage de la phrase\n",
    "    clean_sentence = remove_special_chars(text)\n",
    "    clean_sentence = to_lowercase(clean_sentence)\n",
    "    clean_sentence = remove_stop_words(clean_sentence)\n",
    "    \n",
    "    # Séquençage et tokenization de la phrase\n",
    "    sequence = tokenizer.texts_to_sequences([text])\n",
    "    padded_sequence = pad_sequences(sequence, maxlen=max_length)\n",
    "    \n",
    "    return padded_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prédiction de l'émotion exprimée dans une phrase selon un modèle\n",
    "def predict_text_emotion(model, text):\n",
    "    # Noms des classes récupérés d'après le modèle\n",
    "    classes_name = ['happy', 'sad', 'angry', 'fear', 'love', 'surprise']\n",
    "\n",
    "    # Prédiction du modèle sur le texte\n",
    "    emotion_scores = model.predict(text)\n",
    "\n",
    "    # Récupération de l'indice de la valeur la plus élevée dans le vecteur de prédiction\n",
    "    predicted_emotion_index = np.argmax(emotion_scores)\n",
    "\n",
    "    # Récupération du nom de l'émotion\n",
    "    predicted_emotion_label = classes_name[predicted_emotion_index]\n",
    "\n",
    "    return predicted_emotion_index, predicted_emotion_label, emotion_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constitution un dictionnaire associant temps de la vidéo à une émotion\n",
    "def get_text_emotions_dict(video_path, model, language='fr', segment_duration=5, segmentation_freq=1):\n",
    "    # segment_duration : les émotions sont prédites sur une séquence de 5 secondes\n",
    "    # segmentation_freq : les émotions sont prédites sur des fenêtres décalées d'1 seconde\n",
    "    \n",
    "    # Dictionnaire des émotions\n",
    "    emotions_dict = {}\n",
    "    \n",
    "    video_duration = VideoFileClip(video_path).duration\n",
    "    start_time = 0\n",
    "    \n",
    "    while start_time + segmentation_freq <= video_duration:\n",
    "        # Découpage en séquence\n",
    "        end_time = start_time + segment_duration\n",
    "        sequence_path = 'temp/temp_sequence.mp4'\n",
    "        # Extrait de 'segment_duration=5' secondes\n",
    "        ffmpeg_extract_subclip(video_path, start_time, end_time, targetname=sequence_path)\n",
    "        \n",
    "        # Transcription de la partie séquencée\n",
    "        transcribed_text = transcribe_video_audio(sequence_path, language)\n",
    "        \n",
    "        # Traduction du français vers l'anglais si nécessaire\n",
    "        sequence_text = transcribed_text\n",
    "        if language == 'fr':\n",
    "            sequence_text = translate_french_to_english(transcribed_text)\n",
    "        \n",
    "        \n",
    "        # Préparation de la séquence pour le modèle\n",
    "        sequence_text = normalize_text(sequence_text)\n",
    "        \n",
    "        # Prédiction par le modèle\n",
    "        predicted_index, predicted_label, scores = predict_text_emotion(model, sequence_text)\n",
    "        \n",
    "        # Temps de la vidéo associée à l'émotion prédite par le modèle\n",
    "        emotions_dict[start_time] = [predicted_index, predicted_label, scores]\n",
    "        # print(\"La phrase : '\", transcribed_text, \"' est associée à : \", predicted_label)\n",
    "        \n",
    "        start_time += segmentation_freq\n",
    "        \n",
    "    # Suppression du fichier de séquence temporaire\n",
    "    if os.path.exists(sequence_path):\n",
    "        os.remove(sequence_path)\n",
    "        \n",
    "    # Ajout d'un dernier timecode pour couvrir toute la durée de la vidéo\n",
    "    emotions_dict[video_duration] = [predicted_index, predicted_label, scores]\n",
    "            \n",
    "    return emotions_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fonctions de traitement du son"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "\n",
    "from pydub import AudioSegment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Traitement de segments audio pour être acceptés en entrée du modèle\n",
    "def preprocess_audio_segment(segment_path):\n",
    "    \n",
    "    # Chargement de l'audio\n",
    "    _, sr = librosa.load(segment_path)\n",
    "    raw_audio = AudioSegment.from_file(segment_path)\n",
    "    \n",
    "    # Chargement des échantillons sous forme de tableau Numpy\n",
    "    samples = np.array(raw_audio.get_array_of_samples(), dtype='float32')\n",
    "    \n",
    "    # Normalisation des données du son\n",
    "    trimmed, _ = librosa.effects.trim(samples, top_db=25)\n",
    "    padded = np.pad(trimmed, (0, 600000 - len(trimmed)), 'constant')\n",
    "    \n",
    "    # Récupération des features\n",
    "    FRAME_LENGTH = 2048\n",
    "    HOP_LENGTH = 512\n",
    "    \n",
    "    zcr = librosa.feature.zero_crossing_rate(y=padded, frame_length=FRAME_LENGTH, hop_length=HOP_LENGTH)\n",
    "    rms = librosa.feature.rms(y=padded, frame_length=FRAME_LENGTH, hop_length=HOP_LENGTH)\n",
    "    mfccs = librosa.feature.mfcc(y=padded, sr=sr, n_mfcc=13, hop_length=HOP_LENGTH)\n",
    "    \n",
    "    # Concaténation des features dans un tableau Numpy\n",
    "    processed_segment = np.concatenate((\n",
    "        np.swapaxes(zcr, 0, 1),\n",
    "        np.swapaxes(rms, 0, 1),\n",
    "        np.swapaxes(mfccs, 0, 1)),\n",
    "        axis=1\n",
    "    )\n",
    "    \n",
    "    processed_segment = processed_segment.astype('float32')\n",
    "    processed_segment = np.expand_dims(processed_segment, axis=0)\n",
    "    \n",
    "    return processed_segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prédiction de l'émotion exprimée dans l'audio selon un modèle\n",
    "def predict_audio_emotion(model, audio):\n",
    "    # Noms des classes récupérés d'après le modèle\n",
    "    classes_name = ['angry', 'fear', 'neutral', 'sad', 'disgust', 'happy']\n",
    "\n",
    "    # Prédiction du modèle sur le texte\n",
    "    emotion_scores = model.predict(audio)\n",
    "\n",
    "    # Récupération de l'indice de la valeur la plus élevée dans le vecteur de prédiction\n",
    "    predicted_emotion_index = np.argmax(emotion_scores)\n",
    "\n",
    "    # Récupération du nom de l'émotion\n",
    "    predicted_emotion_label = classes_name[predicted_emotion_index]\n",
    "\n",
    "    return predicted_emotion_index, predicted_emotion_label, emotion_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_audio_emotions_dict(video_path, model, segment_duration=5, segmentation_freq=1):\n",
    "    # segment_duration : les émotions sont prédites sur une séquence de 5 secondes\n",
    "    # segmentation_freq : les émotions sont prédites sur des fenêtres décalées d'1 seconde\n",
    "    \n",
    "    temp_audio_file = 'temp/temp_audio.wav'\n",
    "    emotions_dict = {}\n",
    "    start_time = 0\n",
    "    video_duration = VideoFileClip(video_path).duration\n",
    "    \n",
    "    while start_time + segmentation_freq <= video_duration:\n",
    "        # Séquençage des audios\n",
    "        end_time = min(start_time + segment_duration, video_duration)\n",
    "        video_clip = VideoFileClip(video_path).subclip(start_time, end_time)\n",
    "        \n",
    "        # Normalisation de l'audio\n",
    "        video_clip.audio.write_audiofile(temp_audio_file)\n",
    "        processed_segment = preprocess_audio_segment(temp_audio_file)\n",
    "        \n",
    "        # Prédiction de l'émotion\n",
    "        predicted_emotion_index, predicted_emotion_label, emotion_scores = predict_audio_emotion(model, processed_segment)\n",
    "        emotions_dict[start_time] = [predicted_emotion_index, predicted_emotion_label, emotion_scores]\n",
    "        \n",
    "        start_time += segmentation_freq\n",
    "        \n",
    "    if os.path.exists(temp_audio_file):\n",
    "        os.remove(temp_audio_file)\n",
    "        \n",
    "    emotions_dict[video_duration] = [predicted_emotion_index, predicted_emotion_label, emotion_scores]\n",
    "    \n",
    "    return emotions_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Writing audio in temp/temp_audio.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step\n",
      "MoviePy - Writing audio in temp/temp_audio.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 58ms/step\n",
      "MoviePy - Writing audio in temp/temp_audio.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 64ms/step\n",
      "MoviePy - Writing audio in temp/temp_audio.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "1/1 [==============================] - ETA: 0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 46ms/step\n",
      "MoviePy - Writing audio in temp/temp_audio.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 64ms/step\n",
      "MoviePy - Writing audio in temp/temp_audio.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 62ms/step\n",
      "MoviePy - Writing audio in temp/temp_audio.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 47ms/step\n",
      "MoviePy - Writing audio in temp/temp_audio.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 49ms/step\n",
      "MoviePy - Writing audio in temp/temp_audio.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 45ms/step\n",
      "MoviePy - Writing audio in temp/temp_audio.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 53ms/step\n"
     ]
    }
   ],
   "source": [
    "# Debug\n",
    "# aed = get_audio_emotions_dict('vidéos/voeux_10sec_low.mp4', audio_model, 1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fonctions annexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Création d'une nouvelle vidéo avec les émotions détectées\n",
    "def add_text_to_video(original_video_path, output_video_path, emotions_dict, label, position=1):\n",
    "    \"\"\"Ajoute sur une nouvelle vidéo les émotions détectées selon un dictionnaire{timecode: emotion}.\n",
    "\n",
    "    Args:\n",
    "        original_video_path (str): chemin vers la vidéo originale.\n",
    "        output_video_path (str): chemin de la nouvelle vidéo.\n",
    "        emotions_dict (dict): dictionnaire associant les temps de la vidéo et l'émotion exprimée.\n",
    "        label (str): label qui sera inscrit sur la vidéo et associée au score de prédiction.\n",
    "        position (int, optional): position du label, par défaut 1.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Chargement de la vidéo\n",
    "    video = VideoFileClip(original_video_path)\n",
    "    \n",
    "    # Transformation en liste des timecodes de la vidéo\n",
    "    change_times = list(emotions_dict.keys())\n",
    "    change_times.sort()\n",
    "    \n",
    "    # Stockage des clips modifiés dans une liste\n",
    "    clips_with_text = []\n",
    "\n",
    "    # Parcours des émotions de la liste\n",
    "    for i in range(len(change_times) - 1):\n",
    "        start_time = change_times[i]\n",
    "        end_time = change_times[i + 1]\n",
    "\n",
    "        # Récupération des émotions correspondant aux timecodes\n",
    "        start_emotion = emotions_dict[start_time]\n",
    "\n",
    "        # Création de sous-clip où l'émotion sera indiquée\n",
    "        subclip = video.subclip(start_time, end_time)\n",
    "        subclip_duration = subclip.duration\n",
    "        \n",
    "        # Récupération du texte à inscrire dans le sous-clip\n",
    "        emotion_label = start_emotion[1]\n",
    "        emotion_proba = np.round(start_emotion[2][0][start_emotion[0]], 5)\n",
    "        emotion_proba_str = str(emotion_proba)\n",
    "        text = emotion_label + \" : \" + emotion_proba_str\n",
    "\n",
    "        # Ajout du texte dans la vidéo pour toutes les frames (durée du sous-clip * FPS (nombre de frames par sec.))\n",
    "        for t in np.linspace(0, subclip_duration, int(subclip_duration * video.fps)):\n",
    "\n",
    "            # Récupération de l'image au temps t\n",
    "            frame = subclip.get_frame(t)\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR) # format BGR pour modification\n",
    "\n",
    "            # Ajout du texte sur l'image selon le label et la position\n",
    "            cv2.putText(frame, f\"{label} : {text}\", (50, 50 * position), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB) # format RGB fin de modification\n",
    "\n",
    "            # Création du clip\n",
    "            text_clip = ImageClip(frame, duration=1 / video.fps)\n",
    "            clips_with_text.append(text_clip)\n",
    "\n",
    "    # Concaténation de tous les clips à la fin du traitement\n",
    "    final_clip = concatenate_videoclips(clips_with_text, method=\"compose\")\n",
    "    # Rajout de l'audio de la vidéo d'origine\n",
    "    final_clip = final_clip.set_audio(video.audio)\n",
    "\n",
    "    # Enregistrement de la vidéo\n",
    "    final_clip.write_videofile(output_video_path, codec='libx264', fps=video.fps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def emotion_recognition_video(original_videopath, output_videopath,\n",
    "                              image_model, text_model, audio_model, language='fr',\n",
    "                              segment_duration=5, segmentation_freq=1):\n",
    "    \n",
    "    # Face Emotion Recognition\n",
    "    fer_videopath = 'temp/temp_fer.mp4'\n",
    "    process_video(original_videopath, fer_videopath, image_model)\n",
    "    \n",
    "    \n",
    "    # Text Emotion Recognition\n",
    "    ter_videopath = 'temp/temp_ter.mp4'\n",
    "    text_emotions_dict = get_text_emotions_dict(\n",
    "        fer_videopath,\n",
    "        text_model,\n",
    "        language,\n",
    "        segment_duration=segment_duration,\n",
    "        segmentation_freq=segmentation_freq\n",
    "    )\n",
    "    add_text_to_video(\n",
    "        original_video_path=fer_videopath,\n",
    "        output_video_path=ter_videopath,\n",
    "        emotions_dict=text_emotions_dict,\n",
    "        label='Text',\n",
    "        position=1\n",
    "    )\n",
    "    \n",
    "    \n",
    "    # Speech Emotion Recognition\n",
    "    audio_emotions_dict = get_audio_emotions_dict(\n",
    "        ter_videopath,\n",
    "        audio_model,\n",
    "        segment_duration=segment_duration,\n",
    "        segmentation_freq=segmentation_freq\n",
    "    )\n",
    "    add_text_to_video(\n",
    "        original_video_path=ter_videopath,\n",
    "        output_video_path=output_videopath,\n",
    "        emotions_dict=audio_emotions_dict,\n",
    "        label='Audio',\n",
    "        position=2\n",
    "    )\n",
    "    \n",
    "    # Suppressions des fichiers temporaires\n",
    "    if os.path.exists(fer_videopath):\n",
    "        os.remove(fer_videopath)\n",
    "    \n",
    "    # Des bugs peuvent survenir avec la suppression du fichier tant que le notebook est ouvert\n",
    "    # La fonction ffmpeg retient parfois la ressources sur le fichier ter_videopath='temp/temp_ter.mp4'\n",
    "    # if os.path.exists(ter_videopath):\n",
    "    #     os.remove(ter_videopath)\n",
    "    \n",
    "    print('Vidéo traitée et disponible : ', output_videopath)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test modalités séparées"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partie image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# original_videopath = 'vidéos/voeux_10sec.mp4'\n",
    "# fer_videopath = 'output/fer_video.mp4'\n",
    "# process_video(original_videopath, fer_videopath, image_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partie texte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ter_videopath = 'output/ter_video.mp4'\n",
    "\n",
    "# text_emotions_dict = get_text_emotions_dict(fer_videopath, text_model)\n",
    "# add_text_to_video(\n",
    "#     original_video_path=fer_videopath,\n",
    "#     output_video_path=ter_videopath,\n",
    "#     emotions_dict=text_emotions_dict,\n",
    "#     label='Text',\n",
    "#     position=1\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partie audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ser_videopath = 'output/ser_video.mp4'\n",
    "\n",
    "# audio_emotions_dict = get_audio_emotions_dict('vidéos/voeux_10sec_low.mp4', audio_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add_text_to_video(\n",
    "#     original_video_path=ter_videopath,\n",
    "#     output_video_path=ser_videopath,\n",
    "#     emotions_dict=audio_emotions_dict,\n",
    "#     label='Audio',\n",
    "#     position=2\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test ensemble des modalités"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 370ms/step\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 85ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "Moviepy - Building video temp/temp_fer.mp4.\n",
      "MoviePy - Writing audio in temp_ferTEMP_MPY_wvf_snd.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video temp/temp_fer.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready temp/temp_fer.mp4\n",
      "Moviepy - Running:\n",
      ">>> \"+ \" \".join(cmd)\n",
      "Moviepy - Command successful\n",
      "MoviePy - Writing audio in temp/temp_audio.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 502ms/step\n",
      "Moviepy - Running:\n",
      ">>> \"+ \" \".join(cmd)\n",
      "Moviepy - Command successful\n",
      "MoviePy - Writing audio in temp/temp_audio.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 32ms/step\n",
      "Moviepy - Running:\n",
      ">>> \"+ \" \".join(cmd)\n",
      "Moviepy - Command successful\n",
      "MoviePy - Writing audio in temp/temp_audio.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 41ms/step\n",
      "Moviepy - Running:\n",
      ">>> \"+ \" \".join(cmd)\n",
      "Moviepy - Command successful\n",
      "MoviePy - Writing audio in temp/temp_audio.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 22ms/step\n",
      "Moviepy - Running:\n",
      ">>> \"+ \" \".join(cmd)\n",
      "Moviepy - Command successful\n",
      "MoviePy - Writing audio in temp/temp_audio.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 49ms/step\n",
      "Moviepy - Running:\n",
      ">>> \"+ \" \".join(cmd)\n",
      "Moviepy - Command successful\n",
      "MoviePy - Writing audio in temp/temp_audio.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 19ms/step\n",
      "Moviepy - Running:\n",
      ">>> \"+ \" \".join(cmd)\n",
      "Moviepy - Command successful\n",
      "MoviePy - Writing audio in temp/temp_audio.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 29ms/step\n",
      "Moviepy - Running:\n",
      ">>> \"+ \" \".join(cmd)\n",
      "Moviepy - Command successful\n",
      "MoviePy - Writing audio in temp/temp_audio.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 24ms/step\n",
      "Moviepy - Running:\n",
      ">>> \"+ \" \".join(cmd)\n",
      "Moviepy - Command successful\n",
      "MoviePy - Writing audio in temp/temp_audio.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 32ms/step\n",
      "Moviepy - Running:\n",
      ">>> \"+ \" \".join(cmd)\n",
      "Moviepy - Command successful\n",
      "MoviePy - Writing audio in temp/temp_audio.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 33ms/step\n",
      "Moviepy - Building video temp/temp_ter.mp4.\n",
      "MoviePy - Writing audio in temp_terTEMP_MPY_wvf_snd.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video temp/temp_ter.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready temp/temp_ter.mp4\n",
      "MoviePy - Writing audio in temp/temp_audio.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step\n",
      "MoviePy - Writing audio in temp/temp_audio.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 135ms/step\n",
      "MoviePy - Writing audio in temp/temp_audio.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "1/1 [==============================] - 0s 190ms/step\n",
      "MoviePy - Writing audio in temp/temp_audio.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "1/1 [==============================] - 0s 229ms/step\n",
      "MoviePy - Writing audio in temp/temp_audio.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 142ms/step\n",
      "MoviePy - Writing audio in temp/temp_audio.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 131ms/step\n",
      "MoviePy - Writing audio in temp/temp_audio.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 95ms/step\n",
      "MoviePy - Writing audio in temp/temp_audio.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 100ms/step\n",
      "MoviePy - Writing audio in temp/temp_audio.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 130ms/step\n",
      "MoviePy - Writing audio in temp/temp_audio.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 138ms/step\n",
      "Moviepy - Building video output/final_video.mp4.\n",
      "MoviePy - Writing audio in final_videoTEMP_MPY_wvf_snd.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video output/final_video.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready output/final_video.mp4\n",
      "Vidéo traitée et disponible :  output/final_video.mp4\n"
     ]
    }
   ],
   "source": [
    "emotion_recognition_video('vidéos/voeux_10sec.mp4', 'output/final_video.mp4', image_model, text_model, audio_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
